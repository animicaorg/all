# Grafana Tempo — single-binary config
# Purpose: receive OpenTelemetry traces via OTLP (gRPC+HTTP) and store locally.
# Suitable for Docker Compose or a small k8s install. Metrics-gen & remote_write
# can be toggled by env without changing structure.

server:
  # Web/metrics/UI port
  http_listen_port: ${TEMPO_HTTP_PORT:-3200}
  log_level: ${TEMPO_LOG_LEVEL:-info}

# Receivers (via distributor)
distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:${TEMPO_OTLP_GRPC_PORT:-4317}
        http:
          endpoint: 0.0.0.0:${TEMPO_OTLP_HTTP_PORT:-4318}

# Ingest → WAL → blocks
ingester:
  trace_idle_period: 10s            # flush idle traces
  max_block_bytes: 1048576          # 1 MiB blocks
  max_block_duration: 5m
  lifecycler:
    ring:
      kvstore:
        store: memberlist           # single-node gossip ring
      replication_factor: 1

# Compaction/retention of blocks
compactor:
  compaction:
    compaction_window: 1h
    max_block_bytes: 10485760       # 10 MiB
    block_retention: ${TEMPO_BLOCK_RETENTION:-48h}
    compacted_block_retention: 10m
    retention_concurrency: 2

# Query path
query_frontend:
  max_outstanding_per_tenant: 100
  search:
    concurrent_jobs: 2

querier:
  frontend_worker:
    frontend_address: 127.0.0.1:9095

# Storage (local by default; swap to s3/gcs/azure if needed)
storage:
  trace:
    backend: ${TEMPO_STORAGE_BACKEND:-local}
    wal:
      path: ${TEMPO_WAL_DIR:-/var/tempo/wal}
    local:
      path: ${TEMPO_DATA_DIR:-/var/tempo/traces}
    # Example S3 config (enable by setting TEMPO_STORAGE_BACKEND=s3 and adding envs):
    # s3:
    #   bucket: ${TEMPO_S3_BUCKET}
    #   endpoint: ${TEMPO_S3_ENDPOINT}
    #   access_key: ${TEMPO_S3_ACCESS_KEY}
    #   secret_key: ${TEMPO_S3_SECRET_KEY}
    #   insecure: ${TEMPO_S3_INSECURE:false}

# Gossip/ring for single-binary (works fine with empty join list)
memberlist:
  bind_port: 7946
  join_members: []   # e.g. ["tempo-0.tempo:7946"] in k8s StatefulSet

# Optional: generate RED/service-graph/span metrics from traces and remote_write to Prometheus.
# Enable by setting TEMPO_METRICS_GEN=true and PROM_REMOTE_WRITE_URL.
metrics_generator:
  registry:
    external_labels:
      cluster: ${CLUSTER_NAME:-devnet}
  traces_storage:
    path: ${TEMPO_DATA_DIR:-/var/tempo/traces}/metrics-gen
  ring:
    kvstore:
      store: memberlist
  processors:
    service-graphs:
      dimensions:
        - cluster
        - namespace
        - service
    span-metrics:
      dimensions:
        - cluster
        - namespace
        - service
  storage:
    remote_write:
      - url: ${PROM_REMOTE_WRITE_URL:-}
        send_exemplars: true
        # Optional auth:
        # basic_auth:
        #   username: ${PROM_REMOTE_WRITE_USER}
        #   password: ${PROM_REMOTE_WRITE_PASS}
  # Gate with env (Tempo treats empty remote_write URL as disabled)
  enabled: ${TEMPO_METRICS_GEN:-false}

# Tenant & ingestion safety rails
overrides:
  ingestion:
    rate_limit_bytes: ${TEMPO_INGEST_RATE_LIMIT_BYTES:-20000000}
    burst_size_bytes: ${TEMPO_INGEST_BURST_BYTES:-40000000}
  # When metrics_generator.enabled=true, select processors:
  metrics_generator_processors:
    - service-graphs
    - span-metrics

usage_report:
  reporting_enabled: ${TEMPO_USAGE_REPORT:-false}
